#  Image Sharpening Using Knowledge Distillation

This project aims to enhance image clarity in real-time applications (like video conferencing) by training a lightweight student model (NAFNet-Tiny) using knowledge distillation from a powerful teacher model (Restormer). It was developed as part of the **Intel Unnati Industrial Training 2025**.

---

## ğŸ“Œ Motivation

- Traditional sharpening techniques (e.g., unsharp masking) often add artifacts and are not real-time friendly.
- Transformer-based models like **Restormer** are highly effective but computationally expensive.
- Goal: Use **Knowledge Distillation (KD)** to train a **compact model** that mimics Restormer's quality but runs efficiently on CPUs.

---

## ğŸ“ Dataset

We curated a custom dataset of ~17,000 high-resolution images from:

- **DIV2K** â€“ 800 images
- **Flickr2K** â€“ 2,650 images
- **COCO** â€“ 10,000+ images
- **Synthetic Text Images** â€“ 2,000 images
- **Gaming Screenshots** â€“ 1,500 images

Dataset available on request

Note: There are few other datasets like GoPro,RealBlur (RealBlur-J / RealBlur-R), etc that you can use directly

### ğŸ’¡ Preprocessing:

- Applied controlled blur: Bicubic downscaling + Gaussian blur
- Added JPEG compression and noise (subset-dependent)
- Extracted non-overlapping `256Ã—256` patches
- Stored in `.png` format for consistency

---

## ğŸ“Š Subset Training Strategy

We followed a **multi-phase training approach** with 8 subsets simulating various degradations:

| Subset | Blur Type | JPEG | Noise | Purpose |
|--------|-----------|------|-------|---------|
| 1      | Heavy     | âœ…   | âŒ    | Initial training |
| 3      | Mixed     | âŒ   | âŒ    | Blur diversity |
| 5      | Mixed     | âœ…   | âœ…    | Realistic corruption |
| 7      | Complex   | âœ…   | âœ…    | High variance |

Each subset allowed the student model to gradually generalize to real-world distortions.

---

## ğŸ—ï¸ Model Architecture

### ğŸ”¹ Teacher: [Restormer](https://github.com/swz30/Restormer)
- Transformer-based image restoration model
- Used official pretrained weights:
  - **Single Image Defocus Deblurring**
  - **Gaussian Color Denoising (Blind)**

###  Student Model: NAFNet-Tiny
NAFNet-Tiny is a lightweight CNN-based version of the original NAFNet, designed for real-time deployment and edge-device compatibility. It retains the core design of NAFNet but drastically reduces parameter count, making it much faster and memory-efficient.

| Feature               | Original NAFNet     | NAFNet-Tiny (Ours) |
|-----------------------|----------------------|---------------------|
| Parameters            | ~17.0M               | ~0.7M               |
| Feature Width         | 64                   | 16                  |
| Total NAFBlocks       | 72                   | 26                  |
| Middle Blocks         | 20                   | 2                   |
| FPS (CPU)             | Slow                 | 15â€“20 FPS           |
| ONNX Export           | âŒ                   | âœ…                  |
| Deployment Ready      | Not suitable         | âœ… Real-time         |


â¡ï¸ Inference Optimization: Despite being ~25Ã— smaller than full NAFNet, the Tiny version preserves much of the teacher's visual fidelity.

ğŸ¯ Knowledge Distillation Strategy
The student model was trained using offline distillation from a pretrained Restormer teacher:
loss = Î± * loss_ground_truth + (1 - Î±) * loss_teacher
Î± was tuned across training phases:

Phase 1 (Heavy Blur): Î± = 0.7

Phase 2 (Mixed Blur): Î± = 0.5

Teacher outputs (.png) were generated using pretrained weights and served as soft supervision.

No normalization was applied â€” raw pixel values from .png were used directly to preserve fidelity.

ğŸ§ª Training & Evaluation
Training Duration: 110 epochs

Patch Size: 256Ã—256

Patch-wise Validation: Done using 100 benchmark images during training

Final Evaluation: ~85 full-resolution (â‰¥1920Ã—1080) images with three blur levels:

Heavy: Bicubic 1.7â€“2.2 + Gaussian 1.2â€“1.5

Medium: Bicubic 1.5 + Gaussian 0.8

Low: Bicubic 1.2 + Gaussian 0.4

### ğŸ”¬ SSIM Comparison (Full Images)

| Blur Level | NAFNet-Tiny (Student) | Restormer (Teacher) |
|------------|------------------------|----------------------|
| Heavy      | 88                     | ~90                  |
| Medium     | 93                     | ~95                  |
| Low        | 95                     | ~96                  |
| **Average**| **â‰ˆ92.0**              | â‰ˆ94.0â€“95.0           |


â¡ï¸ The student closely matched Restormer performance, especially on medium and low blur cases, with only ~4% parameter cost.

ğŸ“Š Human Visual Evaluation (Survey)
Users were shown:

Blurred Input

Ground Truth

Teacher Output

Student Output

Asked to rate sharpness on a scale of 1â€“5

### ğŸ§  Visual Quality Survey (Average Ratings / 5)

| Output Type     | Average Rating |
|------------------|----------------|
| Blurred Image    | 3.0            |
| Teacher Output   | 3.7            |
| Student Output   | **4.3**        |
| Ground Truth     | 5.0            |


â¡ï¸ NAFNet-Tiny was consistently rated closer to ground truth, sometimes outperforming the teacher in perceived sharpness due to cleaner edges.

âš™ï¸ Real-Time Ready
Converted to ONNX for efficient deployment

Runs at 15â€“20 FPS on CPU (Intel Core i5)

Compatible with:

OBS Studio virtual camera

Zoom / Google Meet / MS Teams

### ğŸš€ Deployment
Student model exported to ONNX

Integrated with OBS Virtual Camera

Scripted real-time inference pipeline using OpenCV
to run depolyment
run: 
python deploy_sharpening.py

Runs in real time on CPU (~15â€“20 FPS) and can enhance webcam feed in Zoom, Meet, etc.

### Student model folder structure looks like
â”œâ”€â”€ nafnet_tiny.py          # Student model definition
â”œâ”€â”€ train_student.py        # Student training script
â”œâ”€â”€ test_student.py         # Evaluation script
â”œâ”€â”€ dataset.py              # Custom dataset loader
â”œâ”€â”€ utils.py                # Utility functions (metrics, saves)
â”œâ”€â”€ deployment.py           # ONNX conversion + webcam pipeline
â”œâ”€â”€ deploy_sharpening.py    # Virtual webcam output
â”œâ”€â”€ README.md               # Project overview


## ğŸ“š References

- [Restormer: Efficient Transformer for High-Resolution Image Restoration (CVPR 2022)](https://github.com/swz30/Restormer)
- [NAFNet: Nonlinear Activation Free Network for Image Restoration (ECCV 2022)](https://github.com/megvii-research/NAFNet)
- [IntelÂ® Unnati Industrial Training Program](https://www.intel.com/content/www/us/en/education/unnati.html)
- [ONNX Runtime](https://onnxruntime.ai)
- [OBS Studio â€“ Open Broadcaster Software](https://obsproject.com)
- [PyTorch Deep Learning Framework](https://pytorch.org)
- [OpenCV â€“ Open Source Computer Vision Library](https://opencv.org)
- [COCO Dataset](https://cocodataset.org)


## ğŸ™Œ Acknowledgements
Developed by:

Jahnavi Gondi

Bhuma Chaitanya Deepika

Ravula Cheruvu Sai Sruthi

Under the guidance of Prof. Meena K, GITAM School of Technology, Bengaluru.
