# ğŸ§  Image Sharpening Using Knowledge Distillation

This project aims to enhance image clarity in real-time applications (like video conferencing) by training a lightweight student model (NAFNet-Tiny) using knowledge distillation from a powerful teacher model (Restormer). It was developed as part of the **Intel Unnati Industrial Training 2025**.

---

## ğŸ“Œ Motivation

- Traditional sharpening techniques (e.g., unsharp masking) often add artifacts and are not real-time friendly.
- Transformer-based models like **Restormer** are highly effective but computationally expensive.
- Goal: Use **Knowledge Distillation (KD)** to train a **compact model** that mimics Restormer's quality but runs efficiently on CPUs.

---

## ğŸ“ Dataset

We curated a custom dataset of ~17,000 high-resolution images from:

- **DIV2K** â€“ 800 images
- **Flickr2K** â€“ 2,650 images
- **COCO** â€“ 10,000+ images
- **Synthetic Text Images** â€“ 2,000 images
- **Gaming Screenshots** â€“ 1,500 images

Dataset available on request

### ğŸ’¡ Preprocessing:

- Applied controlled blur: Bicubic downscaling + Gaussian blur
- Added JPEG compression and noise (subset-dependent)
- Extracted non-overlapping `256Ã—256` patches
- Stored in `.png` format for consistency

---

## ğŸ“Š Subset Training Strategy

We followed a **multi-phase training approach** with 8 subsets simulating various degradations:

| Subset | Blur Type | JPEG | Noise | Purpose |
|--------|-----------|------|-------|---------|
| 1      | Heavy     | âœ…   | âŒ    | Initial training |
| 3      | Mixed     | âŒ   | âŒ    | Blur diversity |
| 5      | Mixed     | âœ…   | âœ…    | Realistic corruption |
| 7      | Complex   | âœ…   | âœ…    | High variance |

Each subset allowed the student model to gradually generalize to real-world distortions.

---

## ğŸ—ï¸ Model Architecture

### ğŸ”¹ Teacher: [Restormer](https://github.com/swz30/Restormer)
- Transformer-based image restoration model
- Used official pretrained weights:
  - **Single Image Defocus Deblurring**
  - **Gaussian Color Denoising (Blind)**

### ğŸ”¹ Student: [NAFNet-Tiny](https://github.com/megvii-research/NAFNet)
- CNN-based lightweight architecture (~0.7M parameters)
- Trained using a distillation loss:
  
  ```python
  loss = Î± * loss_ground_truth + (1 - Î±) * loss_teacher
With Î± values like 0.7, 0.5 for different phases.

ğŸ§ª Training & Evaluation
Trained for 110 epochs

Intermediate validation used benchmark patch set

Final evaluation used 85 full-resolution blurred images (â‰¥1920Ã—1080)

âœ… SSIM Scores (Full Images):
Blur Level	SSIM
Heavy	88
Medium	93
Low	95

âœ… Survey Results:
Human users rated sharpened outputs (avg. score ~4.3/5)

Student model closely matched teacher outputs visually

ğŸš€ Deployment
Student model exported to ONNX

Integrated with OBS Virtual Camera

Scripted real-time inference pipeline using OpenCV
to run depolyment
run: 
python deploy_sharpening.py

Runs in real time on CPU (~15â€“20 FPS) and can enhance webcam feed in Zoom, Meet, etc.

### Student model folder structure looks like
â”œâ”€â”€ nafnet_tiny.py          # Student model definition
â”œâ”€â”€ train_student.py        # Student training script
â”œâ”€â”€ test_student.py         # Evaluation script
â”œâ”€â”€ dataset.py              # Custom dataset loader
â”œâ”€â”€ utils.py                # Utility functions (metrics, saves)
â”œâ”€â”€ deployment.py           # ONNX conversion + webcam pipeline
â”œâ”€â”€ deploy_sharpening.py    # Virtual webcam output
â”œâ”€â”€ README.md               # Project overview

### ğŸ“š References
Restormer GitHub

NAFNet GitHub

IntelÂ® Unnati Program

ONNX Runtime

OBS Studio

### ğŸ™Œ Acknowledgements
Developed by:

Jahnavi Gondi

Bhuma Chaitanya Deepika

Ravula Cheruvu Sai Sruthi

Under the guidance of Prof. Meena K, GITAM School of Technology, Bengaluru.
